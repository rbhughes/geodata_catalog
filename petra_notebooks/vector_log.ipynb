{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e18e5b3",
   "metadata": {},
   "source": [
    "```\n",
    "bryan@ichabod mac_bucket % for file in *_vector_log.json; do\n",
    "  databricks fs cp \"$file\" dbfs:/Volumes/geodata/petra/vector_log_raw/\n",
    "done\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").load(\"/Volumes/geodata/petra/vector_log_raw/\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.transforms import string_to_iso_date, generate_hash, replace_10e30_with_null\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_flat = df.select(\n",
    "    F.col(\"repo_id\"),\n",
    "    F.col(\"uwi.uwi\").alias(\"uwi\"),\n",
    "    F.col(\"uwi.wsn\").alias(\"wsn\"),\n",
    "    # F.col(\"logdata.digits\").alias(\"digits\"),\n",
    "    F.col(\"logdata.elev_fid\").alias(\"elev_fid\"),\n",
    "    F.col(\"logdata.elev_zid\").alias(\"elev_zid\"),\n",
    "    F.col(\"logdata.ldsn\").alias(\"ldsn\"),\n",
    "    F.col(\"logdata.lsn\").alias(\"lsn\"),\n",
    "    F.col(\"logdata.maxval\").alias(\"maxval\"),\n",
    "    F.col(\"logdata.mean\").alias(\"mean\"),\n",
    "    F.col(\"logdata.minval\").alias(\"minval\"),\n",
    "    F.col(\"logdata.nullval\").alias(\"nullval\"),\n",
    "    F.col(\"logdata.numpts\").alias(\"numpts\"),\n",
    "    F.col(\"logdata.remarks\").alias(\"remarks\"),\n",
    "    F.col(\"logdata.source\").alias(\"source\"),\n",
    "    F.col(\"logdata.start\").alias(\"start\"),\n",
    "    F.col(\"logdata.stddev\").alias(\"stddev\"),\n",
    "    F.col(\"logdata.step\").alias(\"step\"),\n",
    "    F.col(\"logdata.stop\").alias(\"stop\"),\n",
    "    F.col(\"logdatax.adddate\").alias(\"app_row_created\"),\n",
    "    F.col(\"logdatax.chgdate\").alias(\"app_row_changed\"),\n",
    "    F.col(\"logdatax.lasid\").alias(\"lasid\"),\n",
    "    F.col(\"logdef.desc\").alias(\"desc\"),\n",
    "    F.col(\"logdef.logname\").alias(\"logname\"),\n",
    "    F.col(\"logdef.units\").alias(\"units\"),\n",
    "    F.col(\"loglas.hdrsize\").alias(\"hdrsize\"),\n",
    "    F.col(\"loglas.lashdr\").alias(\"lashdr\"),\n",
    ")\n",
    "\n",
    "df_vector_log = df_flat\n",
    "\n",
    "\n",
    "# enforce timestamp for dates\n",
    "for col_name in [\"app_row_created\", \"app_row_changed\"]:\n",
    "    df_vector_log = string_to_iso_date(df_vector_log, col_name, col_name)\n",
    "\n",
    "\n",
    "# ensure real nulls\n",
    "for col_name in [\n",
    "    \"maxval\",\n",
    "    \"mean\",\n",
    "    \"minval\",\n",
    "    \"nullval\",\n",
    "    \"start\",\n",
    "    \"stddev\",\n",
    "    \"step\",\n",
    "    \"stop\",\n",
    "]:\n",
    "    df_vector_log = replace_10e30_with_null(df_vector_log, col_name, col_name)\n",
    "\n",
    "\n",
    "# add id hash\n",
    "id_columns = [\"repo_id\", \"uwi\"]\n",
    "df_vector_log = generate_hash(df_vector_log, \"id\", \"vector_log\", *id_columns)\n",
    "\n",
    "\n",
    "display(df_vector_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.transforms import upsert_dataframe_to_table\n",
    "\n",
    "result = upsert_dataframe_to_table(df_vector_log, \"geodata.petra.vector_log_bronze\")\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
