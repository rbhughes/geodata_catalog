{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e18e5b3",
   "metadata": {},
   "source": [
    "```\n",
    "bryan@ichabod mac_bucket % for file in *_vector_log.json; do\n",
    "  databricks fs cp \"$file\" dbfs:/Volumes/geodata/petra/vector_log/\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load(\"/Volumes/geodata/petra/vector_log/\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.transforms import string_to_iso_date, generate_hash\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_flat = df.select(\n",
    "    F.col(\"repo_id\"),\n",
    "    F.col(\"uwi.uwi\").alias(\"uwi\"),\n",
    "    F.col(\"uwi.wsn\").alias(\"wsn\"),\n",
    "    # F.col(\"logdata.digits\").alias(\"digits\"),\n",
    "    F.col(\"logdata.maxval\").alias(\"max_val\"),\n",
    "    F.col(\"logdata.minval\").alias(\"min_val\"),\n",
    "    F.col(\"logdata.mean\").alias(\"mean\"),\n",
    "    F.col(\"logdata.stddev\").alias(\"std_dev\"),\n",
    "    F.col(\"logdata.numpts\").alias(\"num_points\"),\n",
    "    F.col(\"logdata.start\").alias(\"start\"),\n",
    "    F.col(\"logdata.stop\").alias(\"stop\"),\n",
    "    F.col(\"logdata.step\").alias(\"step\"),\n",
    "    F.col(\"logdata.remarks\").alias(\"remarks\"),\n",
    "    F.col(\"logdata.source\").alias(\"source\"),\n",
    "    F.col(\"logdatax.adddate\").alias(\"app_row_created\"),\n",
    "    F.col(\"logdatax.chgdate\").alias(\"app_row_changed\"),\n",
    "    F.col(\"logdef.desc\").alias(\"description\"),\n",
    "    F.col(\"logdef.logname\").alias(\"log_name\"),\n",
    "    F.col(\"logdef.units\").alias(\"units\")\n",
    ")\n",
    "\n",
    "date_columns = [\n",
    "    \"app_row_created\",\n",
    "    \"app_row_changed\"\n",
    "]\n",
    "\n",
    "df_vector_log = df_flat\n",
    "\n",
    "\n",
    "# enforce timestamp for dates\n",
    "for col_name in date_columns:\n",
    "    df_vector_log = string_to_iso_date(df_vector_log, col_name, col_name)\n",
    "\n",
    "# add id hash\n",
    "id_columns = [\"repo_id\", \"uwi\"]\n",
    "df_vector_log = generate_hash(df_vector_log, \"id\", \"vector_log\", *id_columns)\n",
    "\n",
    "\n",
    "display(df_vector_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
